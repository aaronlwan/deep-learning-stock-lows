{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FRLcfpyoixTP",
        "M8gPJDKE9gg2",
        "g0JOIYEjqs5V",
        "L4Ku7hEq-LSS",
        "JqcQs0zv3rmW"
      ],
      "toc_visible": true,
      "mount_file_id": "19jTFkWDq4eQdxbOdg_mo8nvlJfBpBT6_",
      "authorship_tag": "ABX9TyNqNWZ7A4VjqDKzqbNKU0VS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mVJLbCZPkkK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5313a5-4489-462e-d2bd-32cd9cb75381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "# Import Modules\n",
        "!pip install yfinance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import math\n",
        "from tensorflow.python.framework import ops\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "765D6wYFbq-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize Data"
      ],
      "metadata": {
        "id": "0j5ab1cNjhkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Data Within Window (min-max)\n",
        "def normalize_in_window(data):\n",
        "  new_data = []\n",
        "  for j in range(len(data)):\n",
        "    prices = []\n",
        "    volumes = []\n",
        "    for i in range(len(data[j])):\n",
        "      if (i + 1) % 5 == 0:\n",
        "        volumes.append(data[j][i])\n",
        "      else:\n",
        "        prices.append(data[j][i])\n",
        "    maxprice = max(prices)\n",
        "    minprice = min(prices)\n",
        "    maxvol = max(volumes)\n",
        "    minvol = min(volumes)\n",
        "    newrow = []\n",
        "    price_index = 0\n",
        "    vol_index = 0\n",
        "    for k in range(len(data[j])):\n",
        "      if (k + 1) % 5 == 0:\n",
        "        newrow.append((volumes[vol_index] - minvol)/(maxvol-minvol))\n",
        "        vol_index += 1\n",
        "      else:\n",
        "        newrow.append((prices[price_index] - minprice)/(maxprice - minprice))\n",
        "        price_index += 1\n",
        "    newrow.append(maxprice)\n",
        "    newrow.append(minprice)\n",
        "    new_data.append(newrow)\n",
        "  data = np.array(new_data)\n",
        "  return data\n",
        "\n",
        "# Normalize Over the Training Timeframe (min-max)\n",
        "def normalize_all(data, train_window):\n",
        "  prices = []\n",
        "  volumes = []\n",
        "  for j in range(train_window):\n",
        "    for i in range(len(data[j])):\n",
        "      if (i + 1)%5 == 0:\n",
        "        volumes.append(data[j][i])\n",
        "      else:\n",
        "        prices.append(data[j][i])\n",
        "  maxprice = max(prices)\n",
        "  minprice = min(prices)\n",
        "  minvol = min(volumes)\n",
        "  maxvol = max(volumes)\n",
        "  print('Max Price:', maxprice)\n",
        "  print('Min Price:', minprice)\n",
        "  new_data = []\n",
        "  for k in range(len(data)):\n",
        "    row = []\n",
        "    for i in range(len(data[k])):\n",
        "      if (i + 1)%5 == 0:\n",
        "        row.append((data[k][i]-minvol)/(maxvol-minvol))\n",
        "      else:\n",
        "        row.append((data[k][i]-minprice)/(maxprice-minprice))\n",
        "    new_data.append(row)\n",
        "  return np.array(new_data)\n",
        "\n",
        "# Standardize over the whole Training Timeframe (0 mean, 1std)\n",
        "def standardize_all(data):\n",
        "  prices = []\n",
        "  volumes = []\n",
        "  for j in range(len(data)):\n",
        "    for i in range(len(data[j])):\n",
        "      if (i + 1)%5 == 0:\n",
        "        volumes.append(data[j][i])\n",
        "      else:\n",
        "        prices.append(data[j][i])\n",
        "  meanprice = np.average(np.array(prices))\n",
        "  stdprice = np.std(np.array(prices))\n",
        "  meanvol = np.sum(np.array(volumes))/len(prices)\n",
        "  stdvol = np.std(np.array(volumes))\n",
        "  print('Mean Price:', meanprice)\n",
        "  print('STD Price:', stdprice)\n",
        "  new_data = []\n",
        "  for k in range(len(data)):\n",
        "    row = []\n",
        "    for i in range(len(data[k])):\n",
        "      if (i + 1)%5 == 0:\n",
        "        row.append((data[k][i]-meanvol)/(stdvol))\n",
        "      else:\n",
        "        row.append((data[k][i]-meanprice)/(stdprice))\n",
        "    new_data.append(row)\n",
        "  return np.array(new_data)\n",
        "\n",
        "def log_normalization(data):\n",
        "  return np.log(data)"
      ],
      "metadata": {
        "id": "5zYVw9RMtwD7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### yfinance Data Processsing"
      ],
      "metadata": {
        "id": "mEMYBWjijVrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Data From Yfinance\n",
        "def getData(ticker, input_interval, input_candles, output_interval):\n",
        "\n",
        "  # Load Input Data\n",
        "  # Input Data Columns: Date, Open, High, Low, Close, Volume\n",
        "  input = yf.download(ticker, interval=input_interval)\n",
        "  input = np.array(pd.DataFrame({'Date': input.index, 'Open': input.values[:, 0], 'High': input.values[:, 1],\n",
        "                         'Low': input.values[:, 2], 'Close': input.values[:, 3],\n",
        "                         'Volume': input.values[:, 5]}))\n",
        "  # Output Data Colums: Date, Low\n",
        "  # Load Output Data\n",
        "  output = yf.download(ticker, interval=output_interval)\n",
        "  output = np.array(pd.DataFrame({'Date': output.index, 'Low': output.values[:, 2]}))\n",
        "  \n",
        "  # Match Input w/ Output\n",
        "  # Matched Data Columns: Repeat (Date, Open, High, Low, Close, Volume) for each input candle, Output Low\n",
        "  data = []\n",
        "  input_dates = list(input[:, 0])\n",
        "  for row in output:\n",
        "    data_row = []\n",
        "    outdate = row[0]\n",
        "    try:\n",
        "      input_index = input_dates.index(outdate)\n",
        "      # Collect the input_candles preceeding the outdate\n",
        "      for i in range(input_candles):\n",
        "        candle = input[input_index - 1 - i][1:]\n",
        "        for item in candle:\n",
        "          data_row.append(item)\n",
        "      data_row.append(row[1])\n",
        "      data.append(data_row)\n",
        "    except: \n",
        "      pass\n",
        "  return np.array(data)"
      ],
      "metadata": {
        "id": "8uxA_LK6wHSQ"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Data\n",
        "data = getData(\"SPY\", \"1d\", 10, \"1d\")\n",
        "print(data.shape)\n",
        "data = normalize_all(data, 7000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug3supUgttdv",
        "outputId": "29b5cb42-5c88-402c-95ca-a88589704359"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "(7374, 51)\n",
            "Max Price: 429.6600036621094\n",
            "Min Price: 42.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intraday Data Processing"
      ],
      "metadata": {
        "id": "DzgorHNniX8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intraday Process (5min to Predict 1hr)\n",
        "input_data = np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/5min.csv', header=None))\n",
        "output_data = np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/1hr.csv', header=None))\n",
        "data = []\n",
        "deleted = []\n",
        "i = 0\n",
        "output_data = output_data[1:]\n",
        "index = 0\n",
        "while True:\n",
        "  try:\n",
        "    # Select 24 candles of data\n",
        "    selection = input_data[i: i+24][:, 1:]\n",
        "    last_timestamp = input_data[i: i+24][:, 0][23]\n",
        "    # Check last candle, if it doesn't match up we just omit from dataset b/c we have a lot of datapoints\n",
        "    if int(last_timestamp[14:16]) == 55:\n",
        "      selection = list(selection.flatten())\n",
        "      selection.append(output_data[index][1])\n",
        "      data.append(selection)\n",
        "      i += 12\n",
        "    else:\n",
        "      deleted.append(index)\n",
        "      difference = int(last_timestamp[14:16]) + 60 - 55\n",
        "      i += int(12 - difference/5)\n",
        "    index += 1\n",
        "  except:\n",
        "    break\n",
        "\n",
        "data = np.array(data)\n",
        "print(data.shape)\n",
        "print(deleted)\n",
        "data = normalize_all(data, 33000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5gNGL7icrih",
        "outputId": "ac62d053-02be-4f6e-f5f0-5e3a802648ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34671, 121)\n",
            "[7, 15, 39, 47, 55, 71, 79, 95, 111, 127, 135, 143, 159, 167, 175, 191, 199, 207, 208, 223, 231, 239, 255, 263, 271, 295, 303, 311, 312, 319, 327, 351, 383, 423, 431, 455, 503, 511, 527, 544, 551, 559, 607, 615, 623, 631, 655, 663, 679, 695, 703, 719, 775, 783, 791, 807, 815, 823, 830, 831, 847, 855, 863, 880, 887, 895, 903, 912, 920, 927, 935, 943, 951, 967, 975, 976, 983, 991, 999, 1007, 1015, 1039, 1047, 1055, 1071, 1079, 1095, 1119, 1127, 1151, 1160, 1167, 1191, 1207, 1231, 1239, 1247, 1263, 1271, 1279, 1287, 1303, 1367, 1391, 1431, 1479, 1495, 1503, 1519, 1711, 1727, 1815, 1820, 1821, 1861, 1965, 1973, 1981, 1997, 2030, 2069, 2077, 2125, 2181, 2221, 2309, 2373, 2405, 2469, 2525, 2573, 2581, 2605, 2629, 2677, 2693, 2717, 2838, 2861, 2973, 3018, 3051, 3171, 3275, 3324, 3403, 3619, 3771, 3824, 3833, 3913, 3930, 3986, 3993, 4009, 4073, 4113, 4153, 4177, 4297, 4441, 4545, 5022, 5821, 5822, 5988, 5989, 7043, 7044, 7045, 7869, 8012, 8013, 9877, 10028, 10029, 11885, 16060, 16061, 17108, 17109, 17940, 17941, 18076, 18077, 19124, 19125, 19949, 20092, 20093, 21956, 21957, 22108, 23374, 23965, 25165, 25606, 25973, 27181, 27462, 27590, 27981, 29174, 29189, 30020, 30021, 30550, 30574, 30590, 30610, 32028, 32180, 32845]\n",
            "Max Price: 427.1205\n",
            "Min Price: 52.0695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1hr to predict 1d\n",
        "from pandas import Timestamp\n",
        "input_data = np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/1hrinput.csv', header=None))\n",
        "output = yf.download('SPY', interval='1d')\n",
        "output_data = np.array(pd.DataFrame({'Date': output.index, 'Low': output.values[:, 2]}))\n",
        "outdates = list(output_data[:, 0])\n",
        "start = outdates.index(Timestamp('2005-01-05 00:00:00'))\n",
        "output_data = output_data[start:]\n",
        "data = []\n",
        "deleted = []\n",
        "i = 0\n",
        "index = 0\n",
        "while True:\n",
        "  try:\n",
        "    # Select 24 candles of data\n",
        "    selection = input_data[i: i+24][:, 1:]\n",
        "    last_timestamp = input_data[i: i+24][:, 0][23]\n",
        "    # Check last candle, if it doesn't match up we just omit from dataset b/c we have a lot of datapoints\n",
        "    if int(last_timestamp[11:13]) == 19:\n",
        "      selection = list(selection.flatten())\n",
        "      selection.append(output_data[index][1])\n",
        "      data.append(selection)\n",
        "      i += 12\n",
        "    else:\n",
        "      deleted.append(index)\n",
        "      difference = int(last_timestamp[11:13]) - 7\n",
        "      i += int(12 - difference)\n",
        "    index += 1\n",
        "  except:\n",
        "    break\n",
        "data = np.array(data)\n",
        "print(data.shape)\n",
        "data = log_normalization(data)"
      ],
      "metadata": {
        "id": "w9eJrL2-1V7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510f1dcc-a8c6-4fe9-f1dc-b8366540200d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "(4167, 121)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1hr to predict 1hr\n",
        "input_data = np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/1hrinputandoutput.csv', header=None))\n",
        "output_data = input_data[:, 3]\n",
        "data = []\n",
        "index = 0\n",
        "output_data = output_data[10:]\n",
        "for i in range(len(output_data)):\n",
        "  row = input_data[i: i+10, 1:]\n",
        "  row = row.flatten()\n",
        "  row = list(row)\n",
        "  row.append(output_data[i])\n",
        "  data.append(row)\n",
        "data = np.array(data)\n",
        "print(data.shape)\n",
        "data = normalize_all(data, 66000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz6FLXvJn0T0",
        "outputId": "1928ce8e-8949-4968-a128-655dd83e9a43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68208, 51)\n",
            "Max Price: 450.094\n",
            "Min Price: 52.0695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "FRLcfpyoixTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Train/Test based on time frame (simulates predicting the future using past data)\n",
        "x = data[:, [i for i in range(50)]]\n",
        "y = np.transpose([data[:, 50]])\n",
        "X_train, X_test, Y_train, Y_test = np.transpose(x[:66000]), np.transpose(x[66000:]), np.transpose(y[:66000]), np.transpose(y[66000:])"
      ],
      "metadata": {
        "id": "piCaaerZcoBO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Layer RNN"
      ],
      "metadata": {
        "id": "M8gPJDKE9gg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Mini-Batches\n",
        "def random_mini_batches(X, Y, mini_batch_size=64):\n",
        "  mini_batches = []\n",
        "  m = X.shape[1]\n",
        "  num_complete_mini_batches = math.floor(m/mini_batch_size)\n",
        "  for k in range(num_complete_mini_batches):\n",
        "    batch_X = X[:, k*mini_batch_size: (k+1)*mini_batch_size]\n",
        "    batch_Y = Y[:, k*mini_batch_size: (k+1)*mini_batch_size]\n",
        "    mini_batches.append((batch_X, batch_Y))\n",
        "  if m % mini_batch_size != 0:\n",
        "    batch_X = X[:, mini_batch_size * num_complete_mini_batches:]\n",
        "    batch_Y = Y[:, mini_batch_size * num_complete_mini_batches:]\n",
        "    mini_batches.append((batch_X, batch_Y))\n",
        "  return mini_batches"
      ],
      "metadata": {
        "id": "GINiSpq8rk_x"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "  X = tf.placeholder(tf.float32, shape=[n_x, None], name='Placeholder_1')\n",
        "  Y = tf.placeholder(tf.float32, shape=[n_y, None], name='Placeholder_2')\n",
        "  h_prev = tf.placeholder(tf.float32, [8, 1], name='h_prev')\n",
        "  return X, Y, h_prev\n"
      ],
      "metadata": {
        "id": "bBossYab9cYx"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y, h_prev = create_placeholders(8, 1)\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))\n",
        "print(h_prev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9F_CJWI9z0x",
        "outputId": "19b36bce-bae1-4944-9463-cb031af7462a"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = Tensor(\"Placeholder_1_1:0\", shape=(8, ?), dtype=float32)\n",
            "Y = Tensor(\"Placeholder_2_1:0\", shape=(1, ?), dtype=float32)\n",
            "Tensor(\"h_prev:0\", shape=(8, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf2\n",
        "\n",
        "def initialize_parameters(parameter_size, hidden_size):\n",
        "  Wa = tf.get_variable(\"Wa\", [hidden_size, parameter_size], initializer = tf2.initializers.GlorotNormal())\n",
        "  Wya = tf.get_variable(\"Wya\", [1, hidden_size], initializer = tf2.initializers.GlorotNormal())\n",
        "  Waa = tf.get_variable(\"Waa\", [hidden_size, hidden_size], initializer = tf2.initializers.GlorotNormal())\n",
        "\n",
        " \n",
        "\n",
        "  ba = tf.get_variable(\"ba\", [hidden_size, 1], initializer=tf.zeros_initializer())\n",
        "  by = tf.get_variable(\"by\", [1, 1], initializer=tf.zeros_initializer())\n",
        "  parameters = {\n",
        "      \"Wa\": Wa,\n",
        "      \"Wya\": Wya,\n",
        "      \"Waa\": Waa,\n",
        "      \"ba\": ba,\n",
        "      \"by\": by,\n",
        "  }\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "Q5BAmVxt97nJ"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters, h_prev, max_batch):\n",
        "  Wa = parameters[\"Wa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        " \n",
        "  a, y = {}, []\n",
        "  a[-1] = h_prev\n",
        "  for t in range(max_batch):\n",
        "    try:\n",
        "      a[t] = tf.nn.relu(tf.add(tf.add(ba, tf.matmul(Waa, a[t - 1])), tf.matmul(Wa, X[:, t:t+1])))\n",
        "      yt = tf.nn.relu(tf.add(tf.matmul(Wya, a[t]), by))\n",
        "      y.append(yt)\n",
        "    except:\n",
        "      pass\n",
        "  return y, a"
      ],
      "metadata": {
        "id": "iWIkORXHBxho"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(predictions, Y):\n",
        "  cost = tf.reduce_mean(tf.math.abs(tf.subtract(predictions, Y)))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "9dtl8jJsLpcn"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 500, print_cost = True, minibatch_size=16):\n",
        "  ops.reset_default_graph()\n",
        "  (n_x, m) = X_train.shape\n",
        "  n_y = Y_train.shape[0]\n",
        "  costs = []\n",
        "  \n",
        "  X, Y, h_prev = create_placeholders(n_x, n_y)\n",
        "  parameters = initialize_parameters(n_x, 8)\n",
        "  preds, h = forward_propagation(X, parameters, h_prev, minibatch_size)\n",
        "  cost = compute_cost(preds, Y)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  print(\"Beginning Training\")\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "      hprevious = np.zeros((8, 1))\n",
        "      epoch_cost = 0                      # Defines a cost related to an epoch\n",
        "      num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "      minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
        "      for i in range(num_minibatches):\n",
        "          # Select a minibatch\n",
        "          (minibatch_X, minibatch_Y) = minibatches[i]\n",
        "          _, minibatch_cost, h_new = sess.run([optimizer, cost, h], feed_dict={X: minibatch_X, Y: minibatch_Y, h_prev: hprevious})\n",
        "          epoch_cost += minibatch_cost\n",
        "          hprevious = h_new[list(h.keys())[-1]]\n",
        "      epoch_cost/=num_minibatches\n",
        "\n",
        "      # Print the cost every epoch\n",
        "      if print_cost == True and epoch % 100 == 0:\n",
        "          print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "      if print_cost == True and epoch % 5 == 0:\n",
        "          costs.append(epoch_cost)\n",
        "\n",
        "    \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per fives)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "\n",
        "    # Save parameters\n",
        "    parameters = sess.run(parameters)\n",
        "    print (\"Parameters have been trained!\")\n",
        "\n",
        "    \n",
        "    return parameters, hprevious"
      ],
      "metadata": {
        "id": "PEdI6DZuPl4v"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, h = model(X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "id": "j2lMgyS6VvkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(X, Y, parameters, hprevious):\n",
        "  Wa = parameters[\"Wa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        "  a, y = {}, []\n",
        "  a[-1] = hprevious\n",
        "  for t in range(X.shape[1]):\n",
        "    a[t] = np.maximum(np.add(np.add(ba, np.matmul(Waa, a[t - 1])), np.matmul(Wa, X[:, t:t+1])), 0)\n",
        "    yt = np.maximum(np.add(np.matmul(Wya, a[t]), by), 0)\n",
        "    y.append(yt)\n",
        "\n",
        "\n",
        "  error = 0\n",
        "  for i in range(len(y)):\n",
        "    error += abs(y[i] - Y[0][i])\n",
        "  print('MAE on Normalized Data', error/len(y))\n",
        "\n",
        "\n",
        "  # Convert prediction back into actual prediction\n",
        "  mre = 0\n",
        "  for i in range(len(y)):\n",
        "    maxprice = 450.6300048828125\n",
        "    minprice = 42.8125\n",
        "    actual_predict = y[i]*(maxprice - minprice) + minprice\n",
        "    true_price = Y[0][i]*(maxprice - minprice) + minprice\n",
        "    #print(actual_predict, true_price)\n",
        "    mre += abs(actual_predict - true_price)/(true_price)\n",
        "  print('MRE on Actual Prices:', mre[0][0]/len(y))\n",
        "\n",
        "compute_accuracy(X_test, Y_test, parameters, h)"
      ],
      "metadata": {
        "id": "H_VmjkZtKVS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4015ec7-7722-4674-e3fe-c5e493bbb4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE on Normalized Data [[0.01034523]]\n",
            "MRE on Actual Prices: 0.009823926364928532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two Layer RNN"
      ],
      "metadata": {
        "id": "g0JOIYEjqs5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "  X = tf.placeholder(tf.float32, shape=[n_x, None], name='Placeholder_1')\n",
        "  Y = tf.placeholder(tf.float32, shape=[n_y, None], name='Placeholder_2')\n",
        "  h_prev = tf.placeholder(tf.float32, [8, 1], name='h_prev')\n",
        "  h2_prev = tf.placeholder(tf.float32, [4, 1], name='h2_prev')\n",
        "  return X, Y, h_prev, h2_prev\n"
      ],
      "metadata": {
        "id": "d4wF0_MWqvSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y, h_prev, h2_prev = create_placeholders(4, 1)\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))\n",
        "print(h_prev)\n",
        "print(h2_prev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2054a40-cf93-4bbc-a8fa-7eaf1d3833f7",
        "id": "JQ4Lw5AiqvSA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = Tensor(\"Placeholder_1_2:0\", shape=(4, ?), dtype=float32)\n",
            "Y = Tensor(\"Placeholder_2_2:0\", shape=(1, ?), dtype=float32)\n",
            "Tensor(\"h_prev_2:0\", shape=(8, 1), dtype=float32)\n",
            "Tensor(\"h2_prev_2:0\", shape=(8, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf2\n",
        "\n",
        "def initialize_parameters(parameter_size, hidden_size):\n",
        "  Wa = tf.get_variable(\"Wa\", [hidden_size, parameter_size], initializer = tf2.initializers.GlorotNormal())\n",
        "  Wya = tf.get_variable(\"Wya\", [hidden_size, hidden_size], initializer = tf2.initializers.GlorotNormal())\n",
        "  Waa = tf.get_variable(\"Waa\", [hidden_size, hidden_size], initializer = tf2.initializers.GlorotNormal())\n",
        "\n",
        "  Wa2 = tf.get_variable(\"Wa2\", [4, hidden_size], initializer = tf2.initializers.GlorotNormal())\n",
        "  Wya2 = tf.get_variable(\"Wya2\", [1, 4], initializer = tf2.initializers.GlorotNormal())\n",
        "  Waa2 = tf.get_variable(\"Waa2\", [4, 4], initializer = tf2.initializers.GlorotNormal())\n",
        "\n",
        "  ba = tf.get_variable(\"ba\", [hidden_size, 1], initializer=tf.zeros_initializer())\n",
        "  ba2 = tf.get_variable(\"ba2\", [4, 1], initializer=tf.zeros_initializer())\n",
        "  by = tf.get_variable(\"by\", [hidden_size, 1], initializer=tf.zeros_initializer())\n",
        "  by2 = tf.get_variable(\"by2\", [1, 1], initializer=tf.zeros_initializer())\n",
        "  parameters = {\n",
        "      \"Wa\": Wa,\n",
        "      \"Wya\": Wya,\n",
        "      \"Waa\": Waa,\n",
        "      \"ba\": ba,\n",
        "      \"by\": by,\n",
        "      \"Wa2\": Wa2,\n",
        "      \"Wya2\": Wya2,\n",
        "      \"Waa2\": Waa2,\n",
        "      \"ba2\": ba2,\n",
        "      \"by2\": by2\n",
        "  }\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "G-i3lp-FqvSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters, h_prev, h2_prev, max_batch):\n",
        "  Wa = parameters[\"Wa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        "  Wa2 = parameters[\"Wa2\"]\n",
        "  Wya2 = parameters[\"Wya2\"]\n",
        "  Waa2 = parameters[\"Waa2\"]\n",
        "  ba2 = parameters[\"ba2\"]\n",
        "  by2 = parameters[\"by2\"]\n",
        "  a, a2, y = {}, {}, []\n",
        "  a[-1] = h_prev\n",
        "  a2[-1] = h2_prev\n",
        "  for t in range(max_batch):\n",
        "    try:\n",
        "      a[t] = tf.nn.relu(tf.add(tf.add(ba, tf.matmul(Waa, a[t - 1])), tf.matmul(Wa, X[:, t:t+1])))\n",
        "      yt = tf.nn.relu(tf.add(tf.matmul(Wya, a[t]), by))\n",
        "      a2[t] = tf.nn.relu(tf.add(tf.add(ba2, tf.matmul(Waa2, a2[t - 1])), tf.matmul(Wa2, yt)))\n",
        "      yt2 = tf.nn.relu(tf.add(tf.matmul(Wya2, a2[t]), by2))\n",
        "      y.append(yt2)\n",
        "    except:\n",
        "      pass\n",
        "  return y, a, a2"
      ],
      "metadata": {
        "id": "aJEfqps1qvSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(predictions, Y):\n",
        "  cost = tf.reduce_mean(tf.math.abs(tf.subtract(predictions, Y)))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "ppzsNAyzqvSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1000, print_cost = True, minibatch_size=8):\n",
        "  ops.reset_default_graph()\n",
        "  (n_x, m) = X_train.shape\n",
        "  n_y = Y_train.shape[0]\n",
        "  costs = []\n",
        "  \n",
        "  X, Y, h_prev, h2_prev = create_placeholders(n_x, n_y)\n",
        "  parameters = initialize_parameters(n_x, 8)\n",
        "  preds, h, h2 = forward_propagation(X, parameters, h_prev, h2_prev, minibatch_size)\n",
        "  cost = compute_cost(preds, Y)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  print(\"Beginning Training\")\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "      hprevious = np.zeros((8, 1))\n",
        "      h2previous = np.zeros((4, 1))\n",
        "      epoch_cost = 0                      # Defines a cost related to an epoch\n",
        "      num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "      minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
        "      for i in range(num_minibatches):\n",
        "          # Select a minibatch\n",
        "          (minibatch_X, minibatch_Y) = minibatches[i]\n",
        "          _, minibatch_cost, h_new, h2_new = sess.run([optimizer, cost, h, h2], feed_dict={X: minibatch_X, Y: minibatch_Y, h_prev: hprevious, h2_prev: h2previous})\n",
        "          epoch_cost += minibatch_cost\n",
        "          hprevious = h_new[list(h.keys())[-1]]\n",
        "          h2previous = h2_new[list(h.keys())[-1]]\n",
        "      epoch_cost/=num_minibatches\n",
        "\n",
        "      # Print the cost every epoch\n",
        "      if print_cost == True and epoch % 100 == 0:\n",
        "          print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "      if print_cost == True and epoch % 5 == 0:\n",
        "          costs.append(epoch_cost)\n",
        "\n",
        "    \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per fives)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "\n",
        "    # Save parameters\n",
        "    parameters = sess.run(parameters)\n",
        "    print (\"Parameters have been trained!\")\n",
        "\n",
        "    \n",
        "    \n",
        "    return parameters, hprevious, h2previous"
      ],
      "metadata": {
        "id": "gm2Xc5QJqvSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, h, h2 = model(X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "51a8f8a8-7f51-41fd-f84e-dd4238a99206",
        "id": "rv-ynd4JqvSD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Training\n",
            "Cost after epoch 0: 0.144653\n",
            "Cost after epoch 100: 0.005205\n",
            "Cost after epoch 200: 0.004715\n",
            "Cost after epoch 300: 0.004512\n",
            "Cost after epoch 400: 0.004501\n",
            "Cost after epoch 500: 0.004506\n",
            "Cost after epoch 600: 0.004503\n",
            "Cost after epoch 700: 0.004484\n",
            "Cost after epoch 800: 0.004449\n",
            "Cost after epoch 900: 0.004469\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters have been trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(X, Y, parameters, hprevious, h2previous):\n",
        "  Wa = parameters[\"Wa\"]\n",
        "  Wya = parameters[\"Wya\"]\n",
        "  Waa = parameters[\"Waa\"]\n",
        "  ba = parameters[\"ba\"]\n",
        "  by = parameters[\"by\"]\n",
        "  Wa2 = parameters[\"Wa2\"]\n",
        "  Wya2 = parameters[\"Wya2\"]\n",
        "  Waa2 = parameters[\"Waa2\"]\n",
        "  ba2 = parameters[\"ba2\"]\n",
        "  by2 = parameters[\"by2\"]\n",
        "  a, a2, y = {}, {}, []\n",
        "  a[-1] = hprevious\n",
        "  a2[-1] = h2previous\n",
        "  for t in range(X.shape[1]):\n",
        "    a[t] = np.maximum(np.add(np.add(ba, np.matmul(Waa, a[t - 1])), np.matmul(Wa, X[:, t:t+1])), 0)\n",
        "    yt = np.maximum(np.add(np.matmul(Wya, a[t]), by), 0)\n",
        "    a2[t] = np.maximum(np.add(np.add(ba2, np.matmul(Waa2, a2[t - 1])), np.matmul(Wa2, yt)), 0)\n",
        "    yt2 = np.maximum(np.add(np.matmul(Wya2, a2[t]), by2), 0)\n",
        "    y.append(yt2)\n",
        "\n",
        "\n",
        "  error = 0\n",
        "  for i in range(len(y)):\n",
        "    error += abs(y[i] - Y[0][i])\n",
        "  print('MAE on Normalized Data', error/len(y))\n",
        "\n",
        "\n",
        "  # Convert prediction back into actual prediction\n",
        "  mre = 0\n",
        "  for i in range(len(y)):\n",
        "    maxprice = 429.6400146484375\n",
        "    minprice = 42.8125\n",
        "    actual_predict = y[i]*(maxprice - minprice) + minprice\n",
        "    true_price = Y[0][i]*(maxprice - minprice) + minprice\n",
        "    #print(actual_predict, true_price)\n",
        "    mre += abs(actual_predict - true_price)/(true_price)\n",
        "  print('MRE on Actual Prices:', mre[0][0]/len(y))\n",
        "\n",
        "compute_accuracy(X_test, Y_test, parameters, h, h2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8236a960-7a2c-4c20-a477-4218715dfaf7",
        "id": "nkFv-X5BqvSD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE on Normalized Data [[0.00938141]]\n",
            "MRE on Actual Prices: 0.00847949196308995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "L4Ku7hEq-LSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv1D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, RNN\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform, glorot_normal\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNHUWu9EYk9x",
        "outputId": "14a74711-5d09-4c89-9d67-4fc9f9de30ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format X data to fit in CNN\n",
        "# Format: m sets of 5xdx1 matricies, where d is the number of candles in the window\n",
        "def format(X, d):\n",
        "  # Each window is a column of X\n",
        "  new_X = []\n",
        "  for i in range(len(X[0])):\n",
        "    col = X[:, i]\n",
        "    sample = np.zeros((5, 1))\n",
        "    # Every 5 datapoints in the column is one column in the sample\n",
        "    bar_data = []\n",
        "    for j in range(len(col)):\n",
        "      bar_data.append(col[j])\n",
        "      if (j + 1) % 5 == 0:\n",
        "        sample = np.concatenate((sample, np.transpose([np.array(bar_data)])), axis=1)\n",
        "        bar_data = []\n",
        "    sample = np.delete(sample, 0, axis=1)\n",
        "    sample = np.expand_dims(sample, 2)\n",
        "    new_X.append(sample)\n",
        "  return np.array(new_X)\n",
        "X_train = format(X_train, 10)\n",
        "print(X_train.shape)\n",
        "Y_train = np.squeeze(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWYnkLIUAjsj",
        "outputId": "7dbf3522-42b5-4a71-a8b5-61e72e43ad32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66000, 5, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Reshape\n",
        "\n",
        "def basic_cnn(input_shape = (5, 10, 1)):\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "  X_input = Input(input_shape)\n",
        "  X = Conv2D(filters=5, kernel_size=(3, 3), padding='valid', kernel_initializer=glorot_normal())(X_input)\n",
        "  X = Conv2D(filters=5, kernel_size=(3, 3), padding='valid', kernel_initializer=glorot_normal())(X_input)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(128, activation='relu', kernel_initializer=glorot_normal())(X)\n",
        "  X = Dense(64, activation='relu', kernel_initializer=glorot_normal())(X)\n",
        "  X = Dense(32, activation='relu', kernel_initializer=glorot_normal())(X)\n",
        "  X = Dense(16, activation='relu', kernel_initializer=glorot_normal())(X)\n",
        "  X = Dense(1, activation='relu', kernel_initializer=glorot_normal())(X)\n",
        "  model = Model(inputs = X_input, outputs = X, name='BasicCNN')\n",
        "  return model"
      ],
      "metadata": {
        "id": "CT8Cf3ZZ-bm8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = format(X_test, 10)\n",
        "Y_test = np.squeeze(Y_test)"
      ],
      "metadata": {
        "id": "FgB7bvX6QLLX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = basic_cnn()\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ee1BEctXNet",
        "outputId": "ac0b3e30-6b45-48c9-bd4d-27013c6dc530"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"BasicCNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 5, 10, 1)]        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 8, 5)           50        \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               15488     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,419\n",
            "Trainable params: 26,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "_FbTGkoVsKg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "predictions = model.predict(X_test)\n",
        "print('Average Error', preds[0])\n",
        "\n",
        "# Convert prediction back into actual prediction\n",
        "mre = 0\n",
        "pred_range = len(predictions)\n",
        "for i in range(pred_range):\n",
        "  maxprice = 450.094\n",
        "  minprice = 52.0695\n",
        "  meanprice = 179.1915384746307\n",
        "  stdprice = 101.32692381699914\n",
        "  actual_predict = predictions[i]*(maxprice - minprice) + minprice\n",
        "  true_price = Y_test[i]*(maxprice - minprice) + minprice\n",
        "  #actual_predict = predictions[i]*stdprice + meanprice\n",
        "  #true_price = Y_test[i]*stdprice + meanprice\n",
        "  mre += abs(actual_predict - true_price)/(true_price)\n",
        "  #print(actual_predict, true_price)\n",
        "print('MRE on Actual Prices:', mre[0]/pred_range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9I3_mTNP6_m",
        "outputId": "8820fab0-910e-4ea2-df72-abfd92b7c6cf"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Error 0.008228409243498574\n",
            "MRE on Actual Prices: 0.0074352810089600915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN-RNN"
      ],
      "metadata": {
        "id": "JqcQs0zv3rmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We want X to have shape m x 5 x d x 1\n",
        "# where m is total samples, d is number of days in each window, and 5 is the \n",
        "# number of features in each day\n",
        "def cnn_rnn_format_x(X, d):\n",
        "  # Each window is a column of X\n",
        "  new_X = []\n",
        "  for i in range(len(X[0])):\n",
        "    col = X[:, i]\n",
        "    sample = np.zeros((5, 1))\n",
        "    # Every 5 datapoints in the column is one column in the sample\n",
        "    bar_data = []\n",
        "    for j in range(len(col)):\n",
        "      bar_data.append(col[j])\n",
        "      if (j + 1) % 5 == 0:\n",
        "        sample = np.concatenate((sample, np.transpose([np.array(bar_data)])), axis=1)\n",
        "        bar_data = []\n",
        "    sample = np.delete(sample, 0, axis=1)\n",
        "    sample = np.expand_dims(sample, 2)\n",
        "    new_X.append(sample)\n",
        "  return np.array(new_X)\n",
        "\n",
        "print(cnn_rnn_format_x(X_train, 10).shape)\n",
        "X_train = cnn_rnn_format_x(X_train, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byZrq33i31Da",
        "outputId": "5750163d-1982-4586-fda0-cf6ec41f23a9"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66000, 5, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, LSTM, Flatten, TimeDistributed, Conv2D, Reshape, SimpleRNN, GRU\n",
        "from keras import Sequential\n",
        "from keras.initializers import glorot_normal, glorot_uniform, HeNormal, HeUniform\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=3, kernel_size=(2, 3), strides=1, padding='valid', kernel_initializer=glorot_normal(), input_shape=(5, 10, 1)))\n",
        "model.add(Conv2D(filters=2, kernel_size=(2, 3), strides=1, padding='valid', kernel_initializer=glorot_normal()))\n",
        "model.add(Reshape((4, 9)))\n",
        "model.add(SimpleRNN(20, activation='relu', kernel_initializer=glorot_normal()))\n",
        "model.add(Dense(1, activation='relu', kernel_initializer=glorot_normal()))\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS4SLpAP7G6b",
        "outputId": "920f772e-066a-44cf-8614-358a194fdd11"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 4, 8, 3)           21        \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 3, 6, 2)           38        \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 4, 9)              0         \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 20)                600       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 680\n",
            "Trainable params: 680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.squeeze(Y_train)\n",
        "X_test = cnn_rnn_format_x(X_test, 10)\n",
        "Y_test = np.squeeze(Y_test)"
      ],
      "metadata": {
        "id": "RimOkgDKAfF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "rcErOAQW8i8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "predictions = model.predict(X_test)\n",
        "print('Mean Error', preds)\n",
        "\n",
        "# Convert prediction back into actual prediction\n",
        "mre = 0\n",
        "overpredict = 0\n",
        "for i in range(len(predictions)):\n",
        "  maxprice = 450.094\n",
        "  minprice = 52.0695\n",
        "  meanprice = 179.1915384746307\n",
        "  stdprice = 101.09464575990093\n",
        "  actual_predict = predictions[i]*(maxprice - minprice) + minprice\n",
        "  true_price = Y_test[i]*(maxprice - minprice) + minprice\n",
        "  #actual_predict = np.exp(predictions[i])\n",
        "  #true_price = np.exp(Y_test[i])\n",
        "  \n",
        "  #actual_predict = predictions[i]*stdprice + meanprice\n",
        "  #true_price = Y_test[i]*stdprice + meanprice\n",
        "  if actual_predict > true_price:\n",
        "    overpredict += 1\n",
        "  mre += abs(actual_predict - true_price)/(true_price)\n",
        "  #print(actual_predict, true_price)\n",
        "print('MRE on Actual Prices:', mre[0]/len(predictions))\n",
        "print('Overpredict Rate', overpredict/len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeH0-OZo9rnB",
        "outputId": "44ff5fd2-e202-4276-a0bb-ddac7068647d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Error 0.001892764839021167\n",
            "MRE on Actual Prices: 0.0017028429591542096\n",
            "Overpredict Rate 0.6132546527462551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation: buy a share at projected low if price reaches the projected low, then sell at close\n",
        "output_data = np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/1hrinputandoutput.csv', header=None))\n",
        "removed = 0\n",
        "output_data = output_data[15:]\n",
        "output_data = output_data[66000:]\n",
        "#print(len(output_data), len(predictions))\n",
        "print('For the test interval, the price of SPY changed from', output_data[0][4], 'to', output_data[len(output_data)-1][4])\n",
        "\n",
        "maxprice = 450.094\n",
        "minprice = 52.0695\n",
        "acc_value = 1000\n",
        "winners = 0\n",
        "buys = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  actual_predict = predictions[i]*(maxprice - minprice) + minprice\n",
        "  true_low = output_data[i][3]\n",
        "  true_close = output_data[i][4]\n",
        "  #print(actual_predict, true_low)\n",
        "  # 0.9942 is a \"correction\" constant to account for the model's error\n",
        "  if true_low < actual_predict*0.9942:\n",
        "    acc_value = acc_value - actual_predict*0.9942+ true_close\n",
        "    if actual_predict*0.9942 <= true_close:\n",
        "      winners += 1\n",
        "    buys += 1\n",
        "    #print('Bought at:', str(actual_predict*0.9942, ' Sold at:', str(true_close), ' Current Acc Value:', str(acc_value))\n",
        "print('This current strategy produces', str((acc_value[0]/1000 - 1)*100)+ \"% Profit over the test timeframe\")\n",
        "print('Winrate:', winners/buys)\n",
        "print('Total Transactions:', buys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcu-54aMrBOb",
        "outputId": "f55ef101-51f9-4b68-acda-acb746d900a7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the test interval, the price of SPY changed from 430.6644 to 413.35\n",
            "This current strategy produces 7.597583007812503% Profit over the test timeframe\n",
            "Winrate: 0.644927536231884\n",
            "Total Transactions: 138\n"
          ]
        }
      ]
    }
  ]
}